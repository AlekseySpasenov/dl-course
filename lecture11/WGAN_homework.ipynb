{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwBxTmh3Am9J"
      },
      "source": [
        "### Задание\n",
        "\n",
        "1) Модифицируйте код и реализуйте [Wasserstein GAN](https://arxiv.org/abs/1701.07875) ([From GAN to WGAN\n",
        "](https://lilianweng.github.io/posts/2017-08-20-gan/)) используя weight clipping. (1 балл)\n",
        "\n",
        "2) Замените  weight clipping на [gradient penalty](https://arxiv.org/pdf/1704.00028v3.pdf). (1 балл)\n",
        "\n",
        "3) Добавьте к обучению WGAN условие на метку, продемонстрируйте [условную генерацию](https://arxiv.org/pdf/1411.1784.pdf).  (1 балл) \n",
        "\n",
        "Напишите отчет о том, что попробовали, какие результаты получили, какую архитектуру использовали, как вам кажется надо обучать GAN, чтобы добиться сходимости? Каждый пункт обязательно сопроводите визуализациями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvhaRP7tAm9E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1jx4dNAAm9G"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    pass\n",
        "\n",
        "config = Config()\n",
        "config.mnist_path = None\n",
        "config.batch_size = 16\n",
        "config.num_workers = 3\n",
        "config.num_epochs = 10\n",
        "config.noise_size = 50\n",
        "config.print_freq = 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qub7m0RoAm9H"
      },
      "outputs": [],
      "source": [
        "train = torchvision.datasets.FashionMNIST(\"fashion_mnist\", train=True, transform=torchvision.transforms.ToTensor(), download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voM1DxvEAm9H"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(train, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJcwiRMDAm9H"
      },
      "outputs": [],
      "source": [
        "len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vv5ieReAm9H"
      },
      "outputs": [],
      "source": [
        "for image, cat in dataloader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "6p6GmSXjAm9H"
      },
      "outputs": [],
      "source": [
        "image.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni1QqWbLAm9I"
      },
      "outputs": [],
      "source": [
        "28*28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dsd-Z6vhAm9I"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential( \n",
        "            nn.Linear(config.noise_size, 200),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(200, 28*28),\n",
        "            nn.Sigmoid())\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28*28, 200),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(200, 50),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(50, 1), \n",
        "            nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GuZPb4xAm9I"
      },
      "outputs": [],
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhqKtwNZAm9I"
      },
      "outputs": [],
      "source": [
        "optim_G = optim.Adam(params=generator.parameters(), lr=0.0001)\n",
        "optim_D = optim.Adam(params=discriminator.parameters(), lr=0.0001)\n",
        "\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PS0wrehAm9J"
      },
      "outputs": [],
      "source": [
        "input = Variable(torch.FloatTensor(config.batch_size, 28*28))\n",
        "noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size))\n",
        "fixed_noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size).normal_(0, 1))\n",
        "label = Variable(torch.FloatTensor(config.batch_size))\n",
        "real_label = 1\n",
        "fake_label = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "w9jF0MABAm9J"
      },
      "outputs": [],
      "source": [
        "ERRD_x = np.zeros(config.num_epochs)\n",
        "ERRD_z = np.zeros(config.num_epochs)\n",
        "ERRG = np.zeros(config.num_epochs)\n",
        "N = len(dataloader)\n",
        "\n",
        "for epoch in range(config.num_epochs):\n",
        "    for iteration, (images, cat) in enumerate(dataloader):\n",
        "        ####### \n",
        "        # Discriminator stage: maximize log(D(x)) + log(1 - D(G(z))) \n",
        "        #######\n",
        "        discriminator.zero_grad()\n",
        "        \n",
        "        # real\n",
        "        label.data.fill_(real_label)\n",
        "        input_data = images.view(images.shape[0], -1)\n",
        "        output = discriminator(input_data)\n",
        "        errD_x = criterion(output, label)\n",
        "        ERRD_x[epoch] += errD_x.item()\n",
        "        errD_x.backward()\n",
        "        \n",
        "        # fake \n",
        "        noise.data.normal_(0, 1)\n",
        "        fake = generator(noise)\n",
        "        label.data.fill_(fake_label)\n",
        "        output = discriminator(fake.detach())\n",
        "        errD_z = criterion(output, label)\n",
        "        ERRD_z[epoch] += errD_z.item()\n",
        "        errD_z.backward()\n",
        "        \n",
        "        optim_D.step()\n",
        "        \n",
        "        ####### \n",
        "        # Generator stage: maximize log(D(G(x))\n",
        "        #######\n",
        "        generator.zero_grad()\n",
        "        label.data.fill_(real_label)\n",
        "        output = discriminator(fake)\n",
        "        errG = criterion(output, label)\n",
        "        ERRG[epoch] += errG.item()\n",
        "        errG.backward()\n",
        "        \n",
        "        optim_G.step()\n",
        "        \n",
        "        if (iteration+1) % config.print_freq == 0:\n",
        "            print('Epoch:{} Iter: {} errD_x: {:.2f} errD_z: {:.2f} errG: {:.2f}'.format(epoch+1,\n",
        "                                                                                            iteration+1, \n",
        "                                                                                            errD_x.item(),\n",
        "                                                                                            errD_z.item(), \n",
        "                                                                                            errG.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MizcsX_xAm9K"
      },
      "outputs": [],
      "source": [
        "noise.data.normal_(0, 1)\n",
        "fake = generator(noise)\n",
        "\n",
        "plt.figure(figsize=(6, 7))\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(fake[i].detach().numpy().reshape(28, 28), cmap=plt.cm.Greys_r)\n",
        "    plt.axis('off')"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}