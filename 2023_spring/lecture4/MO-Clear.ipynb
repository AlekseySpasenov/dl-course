{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 7: \"Методы оптимизации\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib import animation\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from torchvision import datasets, transforms\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "plt.rc('animation', html='html5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом семинаре мы попробуем сравнить различные методы оптимизации: GD, Momentum, NAG, Adagrad, RMSProp, Adadelta, Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1: Реализация методов"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для всех экспериментов подберите параметры так, чтобы метод сошелся к ближайшему локальному минимуму. Все методы следует запускать из одной и той же точки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/dzlab/deepprojects/blob/master/visualization/Optimizers_in_Action.ipynb\n",
    "\n",
    "def grid_samples(center=[0, 0], offset=5, size=100):\n",
    "    range1 = np.linspace(center[0]-offset, center[0]+offset, size)\n",
    "    range2 = np.linspace(center[1]-offset, center[1]+offset, size)\n",
    "    return torch.from_numpy(np.stack(np.meshgrid(range1, range2))).float()\n",
    "\n",
    "\n",
    "def mse(y, y_hat):\n",
    "    return ((y - y_hat) ** 2).mean(axis=-1)\n",
    "\n",
    "\n",
    "def msre(y, y_hat):\n",
    "    return ((y - y_hat) ** 2).mean(axis=-1).sqrt()\n",
    "\n",
    "\n",
    "def mae(y, y_hat):\n",
    "    return ((y - y_hat).abs()).mean(axis=-1)\n",
    "\n",
    "\n",
    "class LossAnimator:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.size = len(X)\n",
    "\n",
    "    def loss_func(self, W, loss):\n",
    "        shape = W.shape\n",
    "        return loss((self.X @ W.view(shape[0], -1)).T, self.y).view(shape[1:])\n",
    "\n",
    "    def plot_loss_funcs(self, weights, fcts, titles, view=(20, 50)):\n",
    "        num_fcts = len(fcts)\n",
    "        fig = plt.figure(figsize=(7 * num_fcts,7))\n",
    "        for i in range(num_fcts):\n",
    "            loss = self.loss_func(weights, loss=fcts[i])\n",
    "            ax = fig.add_subplot(1, num_fcts, i+1, projection='3d')\n",
    "            ax.plot_surface(*weights, loss, cmap='viridis')\n",
    "            ax.set_xlabel('w0'); ax.set_ylabel('w1'); ax.set_zlabel('Loss')\n",
    "            ax.set_title(titles[i])\n",
    "            ax.view_init(*view)\n",
    "\n",
    "    def _init_animation(self, epochs, train_data):\n",
    "        self.train_data = train_data\n",
    "        self.epochs = epochs\n",
    "        self.nmethods = len(train_data)\n",
    "\n",
    "        weights = grid_samples(offset=5)\n",
    "\n",
    "        max_loss = max([data['losses'].max() for data in train_data.values()])\n",
    "        loss_curve = self.loss_func(weights, loss=mse)\n",
    "        colors = cm.rainbow(np.linspace(0, 1, self.nmethods))\n",
    "\n",
    "\n",
    "        self.fig = plt.figure(figsize=(14, 8))\n",
    "        self.gs = GridSpec(2, 2, width_ratios=[1, 2.5])\n",
    "\n",
    "        self.ax0 = self.fig.add_subplot(self.gs[0,0])\n",
    "        self.lines0 = {\n",
    "            name: self.ax0.plot([], [], c=c, label=name)[0]\n",
    "            for name, c in zip(train_data.keys(), colors)\n",
    "        }\n",
    "        self.ax0.scatter(self.X[:,0], self.y, c='orange', label='Ground truth')\n",
    "        self.ax0.set_ylim(self.y.min(), self.y.max())\n",
    "        self.ax0.set_title('Ground truth & Model', fontsize=16)\n",
    "        self.ax0.legend(loc='lower right')\n",
    "\n",
    "        self.ax1 = self.fig.add_subplot(self.gs[:,1], projection='3d')\n",
    "        self.ax1.plot_surface(*weights, loss_curve-0.5, cmap='viridis', alpha=0.8)\n",
    "        self.ax1.view_init(50, 70)\n",
    "        self.lines1 = {\n",
    "            name: self.ax1.plot3D([], [], [], c=c, marker='o', alpha=0.9, label=name)[0]\n",
    "            for name, c in zip(train_data.keys(), colors)\n",
    "        }\n",
    "        self.ax1.set_title('Loss', fontsize=16, pad=20)\n",
    "        self.ax1.set_xlabel('w0')\n",
    "        self.ax1.set_ylabel('w1')\n",
    "        self.ax1.set_zlabel('Loss')\n",
    "        self.ax1.legend()\n",
    "\n",
    "        self.ax2 = self.fig.add_subplot(self.gs[1,0])\n",
    "        self.lines2 = {\n",
    "            name: self.ax2.plot([], [], c=c, label=name)[0]\n",
    "            for name, c in zip(train_data.keys(), colors)\n",
    "        }\n",
    "        self.ax2.set_title('Loss', fontsize=16)\n",
    "        self.ax2.set_ylabel('loss')\n",
    "        self.ax2.set_ybound(0, max_loss)\n",
    "        self.ax2.set_xlim(0, epochs)\n",
    "        self.ax2.legend(loc='center right')\n",
    "\n",
    "        self.fig.tight_layout()\n",
    "        self.fig.subplots_adjust(top=0.85)\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "        return self.fig\n",
    "\n",
    "    def _animate(self, i):   \n",
    "        steps = np.arange(i+1)\n",
    "        left = max(0, i-20)\n",
    "        for name, data in self.train_data.items():\n",
    "            # plot ground truth & model\n",
    "            self.lines0[name].set_data(self.X[:, 0], self.X @ data['weights'][i])\n",
    "\n",
    "            # plot loss (output of the sampling)\n",
    "            self.lines1[name].set_data(data['weights'][left:i+1, 0], data['weights'][left:i+1, 1])\n",
    "            self.lines1[name].set_3d_properties(data['losses'][left:i+1])\n",
    "\n",
    "            self.lines2[name].set_data(steps, data['losses'][:i+1])\n",
    "\n",
    "        self.fig.suptitle(f'Epoch: {i}/{self.epochs}', fontsize=22)\n",
    "    \n",
    "    def animate(self, epochs, train_data, step_skip=1):\n",
    "        self._init_animation(epochs, train_data)\n",
    "        anim = animation.FuncAnimation(self.fig, self._animate, frames=range(0, epochs, step_skip), interval=100 * step_skip)\n",
    "        return HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100\n",
    "X = torch.ones(size, 2)\n",
    "X[:, 0].uniform_(-1., 1)\n",
    "\n",
    "y_hat = 3 * X[:, 0] + 2\n",
    "y = y_hat + torch.randn(size)\n",
    "\n",
    "loss_animator = LossAnimator(X, y)\n",
    "\n",
    "plt.scatter(loss_animator.X[:,0], loss_animator.y, label='y');\n",
    "plt.scatter(loss_animator.X[:,0], y_hat, label='y_hat');\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = grid_samples()\n",
    "loss_animator.plot_loss_funcs(weights, [mse, msre, mae], ['MSE', 'MSRE', 'MAE'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 1.1 Реализуйте методы SGD, Momentum, NAG, Adagrad, Adadelta, Adam.</i> **(1 балл)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params):\n",
    "        self.params = list(params)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.detach_()\n",
    "                param.grad.zero_()\n",
    "    \n",
    "    def pre_step(self):\n",
    "        pass\n",
    "    \n",
    "    def step(self):\n",
    "        pass\n",
    "    \n",
    "    def update_param(self, p):\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_function(fn, optim, optim_args, start_point, num_iter = 50):\n",
    "    weigths = nn.Parameter(torch.FloatTensor(start_point), requires_grad=True)\n",
    "\n",
    "    optim = optim(params=[weigths], **optim_args)\n",
    "    points = []\n",
    "    losses = []\n",
    "    for i in range(num_iter):\n",
    "        if hasattr(optim, 'pre_step'):\n",
    "            optim.pre_step()\n",
    "        loss = fn(weigths)\n",
    "        points.append(weigths.data.detach().clone())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "    points = torch.stack(points, axis=0)\n",
    "    losses = torch.FloatTensor(losses)\n",
    "    return points, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_optimizers(\n",
    "    loss_animator,\n",
    "    fn,\n",
    "    optim_list,\n",
    "    start_point,\n",
    "    num_iter = 50,\n",
    "    step_skip = 1\n",
    "):\n",
    "    data = {}\n",
    "    loss_func = partial(loss_animator.loss_func, loss=fn)\n",
    "    for name, optim, args in optim_list:\n",
    "        points, losses = optimize_function(loss_func, optim, args, start_point, num_iter)\n",
    "        data[name] = {\n",
    "            'weights': points,\n",
    "            'losses': losses,\n",
    "        }\n",
    "    \n",
    "    return loss_animator.animate(num_iter, data, step_skip=step_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    def __init__(self, params, lr=1e-2):\n",
    "        super().__init__(params)\n",
    "        self.lr = lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                p -= self.lr * p.grad\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "points, losses = optimize_function(partial(loss_animator.loss_func, loss=mse), SGD, {'lr': 1e-1}, start_point=[-20, -20], num_iter=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<i1> 1.2 Сравните реализованные методы на предложенном примере **(1 балл)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Часть 2: Обучение нейронной сети"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 2.1 Сравните графики обучения для полносвязной нейросети на методах Adam, Adagrad, AdaDelta и SGD (на MNIST). Для обучения используйте оптимизаторы из первой части, а не из pytorch. </i> **(2 балла)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('.', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('.', train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 2.2 Сравните графики обучения для сверточной нейросети на методах Adam, Adagrad, AdaDelta и SGD. </i> **(1 балл)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feedback (опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы можете оставить список опечаток из лекции или семинара:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы можете оставить комментарии по лекции или семинару:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Dec  7 2022, 10:16:11) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "vscode": {
   "interpreter": {
    "hash": "87f2c61721633f38491d53c2bfdcc0361799add3518de6ab4d9ab97e249bd1f3"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
